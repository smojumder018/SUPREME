{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smojumder018/SUPREME/blob/main/3.1%20CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtEKzHH1VnnM"
      },
      "source": [
        "#Convolutional Neural Network with PyTorch\n",
        "## 1. About Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scz3eBjmVnnN"
      },
      "source": [
        "### Transition From Feedforward Neural Network\n",
        "\n",
        "\n",
        "#### Basic Convolutional Neural Network\n",
        "- Additional **convolution** and **pooling** layers **before feedforward neural network**\n",
        "- Layer with a **linear function & non-linearity**: **Fully connected layer**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. MNIST Dataset\n",
        "![](https://drive.google.com/uc?export=view&id=1Esgjfx-jfstlL0h1dlfBvcjGVGSFzMrw)\n",
        "\n",
        "The MNIST dataset is a benchmark dataset used for training and testing image processing systems, especially in the field of machine learning and deep learning. It is particularly popular for testing classification algorithms. It is a collection of images of hand written numbers.\n",
        "\n",
        "**Datasets:**\n",
        "\n",
        "Set| Number of Images\n",
        "---|---\n",
        "Training|60,000\n",
        "Testing|10,000\n",
        "\n",
        "**Image Properties:**\n",
        "\n",
        "*Image Size: 28 x 28 pixels\n",
        "\n",
        "*Pixel Values: 0 (black) to 255 (white); typically normalized to [0, 1] for model input\n",
        "\n",
        "*Color Format: Grayscale (1 channel)\n"
      ],
      "metadata": {
        "id": "bFKu7X7m0kLw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "KFSacDhsVnnP"
      },
      "source": [
        "## 3. Building a Convolutional Neural Network with PyTorch\n",
        "\n",
        "### Model A:\n",
        "- 2 Convolutional Layers\n",
        "    - Same Padding (same output size)\n",
        "- 2 Max Pooling Layers\n",
        "- 1 Fully Connected Layer\n",
        "\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- Step 3: Create Model Class\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGsX8i2kVnnP"
      },
      "source": [
        "### Step 1: Loading MNIST Train Dataset\n",
        "**Images from 1 to 9**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ld9UgMJCVnnP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGhvro_PVnnQ",
        "outputId": "3aca3bae-f404-4f66-a156-98d82299eeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 339kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.71MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.30MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXS4EWhEVnnR"
      },
      "source": [
        "### Step 2: Make Dataset Iterable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tWJurrNNVnnS"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = 5\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model Class\n"
      ],
      "metadata": {
        "id": "S4deeLVQHi5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ngJeyfh-VnnS"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Max pool 1\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Max pool 2\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution 1\n",
        "        out = self.cnn1(x)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Max pool 1\n",
        "        out = self.maxpool1(out)\n",
        "\n",
        "        # Convolution 2\n",
        "        out = self.cnn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Max pool 2\n",
        "        out = self.maxpool2(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1) #Converts [32, 7, 7] into a single vector of size 32×7×7 = 1568\n",
        "\n",
        "        # Linear function (readout)\n",
        "        out = self.fc1(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Input: 1×28×28 grayscale image\n",
        "\n",
        "$$\n",
        "\\text{Output Shape} = \\left\\lfloor \\frac{\\text{Input} - \\text{Kernel} + 2 \\times \\text{Padding}}{\\text{Stride}} \\right\\rfloor + 1\n",
        "$$\n",
        "\n",
        "\n",
        "  1. Conv2d Layer 1:\n",
        "  nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "  Output shape: ((28 - 5 + 2×2)/1) + 1 = 28\n",
        "\n",
        "  [batch, 16, 28, 28]\n",
        "\n",
        "  Params: (1×5×5 + 1 bias) × 16 = 416\n",
        "\n",
        "  2. ReLU:\n",
        "\n",
        "  Output shape: [batch, 16, 28, 28]\n",
        "\n",
        "  No params\n",
        "\n",
        "  3. MaxPool2d:\n",
        "  nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "  Output shape: Takes max of 2x2 patches halving\n",
        "  \n",
        "  [batch, 16, 14, 14]\n",
        "\n",
        "  No params\n",
        "\n",
        "  4. Conv2d Layer 2:\n",
        "  nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "  Output shape: ((14 - 5 + 2×2)/1) + 1 = 14\n",
        "  \n",
        "  [batch, 32, 14, 14]\n",
        "\n",
        "  Params: (16×5×5 + 1 bias) × 32 = 12,832\n",
        "\n",
        "  5. ReLU:\n",
        "\n",
        "  Output shape: [batch, 32, 14, 14]\n",
        "\n",
        "  No params\n",
        "\n",
        "  6. MaxPool2d:\n",
        "\n",
        "  Output shape: [batch, 32, 7, 7]\n",
        "\n",
        "  No params\n",
        "\n",
        "  7. Flatten:\n",
        "\n",
        "  [32, 7, 7] → 1568\n",
        "\n",
        "  8. Fully Connected Layer:\n",
        "  nn.Linear(1568, 10)\n",
        "\n",
        "  Output shape: [batch, 10]\n",
        "\n",
        "  Params: 1568×10 + 10 = 15,690"
      ],
      "metadata": {
        "id": "4gW5CB5mVDmr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gRtgU5RVnnS"
      },
      "source": [
        "### Step 4: Instantiate Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mUech_AVnnS",
        "outputId": "7f58437d-3257-4da3-882f-df1b23f3537e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             416\n",
            "              ReLU-2           [-1, 16, 28, 28]               0\n",
            "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
            "            Conv2d-4           [-1, 32, 14, 14]          12,832\n",
            "              ReLU-5           [-1, 32, 14, 14]               0\n",
            "         MaxPool2d-6             [-1, 32, 7, 7]               0\n",
            "            Linear-7                   [-1, 10]          15,690\n",
            "================================================================\n",
            "Total params: 28,938\n",
            "Trainable params: 28,938\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.32\n",
            "Params size (MB): 0.11\n",
            "Estimated Total Size (MB): 0.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "model = CNNModel()\n",
        "#Shows what the model looks like\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2mXbPOeVnnS"
      },
      "source": [
        "### Step 5: Instantiate Loss Class\n",
        "\n",
        "  1. nn.MSELoss (Mean Squared Error Loss)\n",
        "\n",
        "  Use: Regression tasks  \n",
        "  Equation:  \n",
        "      MSE = (1/n) * Σ (yᵢ - ŷᵢ)²  \n",
        "\n",
        "\n",
        "  2. nn.L1Loss (Mean Absolute Error Loss)\n",
        "\n",
        "  Use: Regression with less sensitivity to outliers  \n",
        "  Equation:  \n",
        "      MAE = (1/n) * Σ |yᵢ - ŷᵢ|  \n",
        "\n",
        "\n",
        "  3. nn.CrossEntropyLoss (Cross Entropy for Classification)\n",
        "\n",
        "  Use: Multi-class classification (logits as output)  \n",
        "  Equation:  \n",
        "      CE = -Σ yᵢ * log(softmax(ŷᵢ))  \n",
        "\n",
        "\n",
        "  4. nn.BCEWithLogitsLoss (Binary Cross Entropy with Logits)\n",
        "\n",
        "  Use: Binary classification (outputs logits)  \n",
        "  Equation:  \n",
        "      BCE = -[y * log(σ(ŷ)) + (1 - y) * log(1 - σ(ŷ))]  \n",
        "      where σ(ŷ) = sigmoid(ŷ)  \n",
        "\n",
        "\n",
        "  5. nn.HuberLoss (Robust Regression)\n",
        "\n",
        "  Use: Regression with robustness to outliers  \n",
        "  Equation:  \n",
        "      L₍δ₎(a) = ½ * a²    if |a| ≤ δ  \n",
        "              δ * (|a| - ½δ) otherwise  \n",
        "      where a = y - ŷ  \n",
        "\n",
        "\n",
        "  6. nn.SmoothL1Loss (Smooth between L1 and L2)\n",
        "\n",
        "  Use: Regression (alternative to MSE/L1)  \n",
        "  Equation:  \n",
        "      Like Huber with δ = 1  \n",
        "\n",
        "\n",
        "  7. nn.KLDivLoss (Kullback-Leibler Divergence)\n",
        "\n",
        "  Use: Comparing probability distributions  \n",
        "  Equation:  \n",
        "      KL(P || Q) = Σ P(i) * log(P(i) / Q(i))  \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i4KoG2XJVnnS"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amdMka1_VnnS"
      },
      "source": [
        "### Step 6: Instantiate Optimizer Class\n",
        "\n",
        "\n",
        "  1. optim.SGD (Stochastic Gradient Descent)\n",
        "\n",
        "  Use: Basic optimizer with optional momentum  \n",
        "  Update Rule:  \n",
        "      θ = θ - lr * ∇L(θ)  \n",
        "  With momentum:  \n",
        "      v = μ * v - lr * ∇L(θ)  \n",
        "      θ = θ + v  \n",
        "  PyTorch:  \n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "  2. optim.Adam (Adaptive Moment Estimation)\n",
        "\n",
        "  Use: Most common; good default choice  \n",
        "  Update Rule:  \n",
        "      mₜ = β₁ * mₜ₋₁ + (1 - β₁) * gₜ  \n",
        "      vₜ = β₂ * vₜ₋₁ + (1 - β₂) * gₜ²  \n",
        "      m̂ₜ = mₜ / (1 - β₁ᵗ), v̂ₜ = vₜ / (1 - β₂ᵗ)  \n",
        "      θ = θ - lr * m̂ₜ / (√v̂ₜ + ε)  \n",
        "  PyTorch:  \n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  3. optim.AdamW (Adam with Weight Decay)\n",
        "\n",
        "  Use: Better regularization than L2 in Adam  \n",
        "  Same update rule as Adam but decouples weight decay  \n",
        "  PyTorch:  \n",
        "      optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "  4. optim.RMSprop\n",
        "\n",
        "  Use: For non-stationary objectives or RNNs  \n",
        "  Update Rule:  \n",
        "      vₜ = α * vₜ₋₁ + (1 - α) * gₜ²  \n",
        "      θ = θ - lr * gₜ / (√vₜ + ε)  \n",
        "  PyTorch:  \n",
        "      optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99)\n",
        "\n",
        "  5. optim.Adagrad\n",
        "\n",
        "  Use: Sparse data, adapts learning rate per parameter  \n",
        "  Update Rule:  \n",
        "      Gₜ = Gₜ₋₁ + gₜ²  \n",
        "      θ = θ - lr * gₜ / (√Gₜ + ε)  \n",
        "  PyTorch:  \n",
        "      optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wJ6Ldi5RVnnS"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx67K2uFVnnS"
      },
      "source": [
        "### Parameters In-Depth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh6-JImwVnnT"
      },
      "source": [
        "### Step 7: Train Model\n",
        "- Process\n",
        "    1. **Convert inputs/labels to variables**\n",
        "        - CNN Input: (1, 28, 28)\n",
        "        - Feedforward NN Input: (1, 28*28)\n",
        "    2. Clear gradient buffets\n",
        "    3. Get output given inputs\n",
        "    4. Get loss\n",
        "    5. Get gradients w.r.t. parameters\n",
        "    6. Update parameters using gradients\n",
        "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "    7. REPEAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6V_EQBGVnnT",
        "outputId": "2a37492e-bbea-4ca8-a7b3-a6a7357a1b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 0.457778662443161. Accuracy: 90.08999633789062\n",
            "Iteration: 1000. Loss: 0.3076566755771637. Accuracy: 93.08999633789062\n",
            "Iteration: 1500. Loss: 0.17826765775680542. Accuracy: 94.30000305175781\n",
            "Iteration: 2000. Loss: 0.18221516907215118. Accuracy: 95.47000122070312\n",
            "Iteration: 2500. Loss: 0.1633397340774536. Accuracy: 96.1500015258789\n",
            "Iteration: 3000. Loss: 0.13475945591926575. Accuracy: 96.4800033569336\n"
          ]
        }
      ],
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.requires_grad_()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "\n",
        "                images = images.requires_grad_()\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "rand_index = random.randint(0, len(test_dataset) - 1)\n",
        "image, label = test_dataset[rand_index]\n",
        "\n",
        "# Prepare image for the model (add batch dimension)\n",
        "input_image = image.unsqueeze(0)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Show the image and prediction\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"True Label: {label}, Predicted: {predicted.item()}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "qJQlNfQDmO9M",
        "outputId": "c8abc835-7fad-411a-d10b-733caa84711b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xN6_8GlVnnT"
      },
      "source": [
        "### Model B:\n",
        "- 2 Convolutional Layers\n",
        "    - Same Padding (same output size)\n",
        "- 2 **Average Pooling** Layers\n",
        "- 1 Fully Connected Layer\n",
        "<img src=\"./images/cnn10-3.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "<img src=\"./images/cnn10-4.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- Step 3: Create Model Class\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpSbdGvfVnnT",
        "outputId": "91835b0f-0e00-4bcb-cd51-8620cf6809dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             416\n",
            "              ReLU-2           [-1, 16, 28, 28]               0\n",
            "         AvgPool2d-3           [-1, 16, 14, 14]               0\n",
            "            Conv2d-4           [-1, 32, 14, 14]          12,832\n",
            "              ReLU-5           [-1, 32, 14, 14]               0\n",
            "         AvgPool2d-6             [-1, 32, 7, 7]               0\n",
            "            Linear-7                   [-1, 10]          15,690\n",
            "================================================================\n",
            "Total params: 28,938\n",
            "Trainable params: 28,938\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.32\n",
            "Params size (MB): 0.11\n",
            "Estimated Total Size (MB): 0.44\n",
            "----------------------------------------------------------------\n",
            "Iteration: 500. Loss: 0.6161680221557617. Accuracy: 85.72000122070312\n",
            "Iteration: 1000. Loss: 0.4195305109024048. Accuracy: 89.19999694824219\n",
            "Iteration: 1500. Loss: 0.40347445011138916. Accuracy: 90.2699966430664\n",
            "Iteration: 2000. Loss: 0.27060747146606445. Accuracy: 90.77999877929688\n",
            "Iteration: 2500. Loss: 0.2848072052001953. Accuracy: 92.41000366210938\n",
            "Iteration: 3000. Loss: 0.2691440284252167. Accuracy: 93.13999938964844\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Average pool 1\n",
        "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
        "\n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Average pool 2\n",
        "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution 1\n",
        "        out = self.cnn1(x)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Average pool 1\n",
        "        out = self.avgpool1(out)\n",
        "\n",
        "        # Convolution 2\n",
        "        out = self.cnn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Max pool 2\n",
        "        out = self.avgpool2(out)\n",
        "\n",
        "        # Resize\n",
        "        # Original size: (100, 32, 7, 7)\n",
        "        # out.size(0): 100\n",
        "        # New out size: (100, 32*7*7)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        out = self.fc1(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "from torchsummary import summary\n",
        "model = CNNModel()\n",
        "\n",
        "#Shows what the model looks like\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images as Variable\n",
        "        images = images.requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images to a Torch Variable\n",
        "                images = images.requires_grad_()\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pick a random index from the test dataset\n",
        "rand_index = random.randint(0, len(test_dataset) - 1)\n",
        "image, label = test_dataset[rand_index]\n",
        "\n",
        "# Prepare image for the model (add batch dimension)\n",
        "input_image = image.unsqueeze(0)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Show the image and prediction\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"True Label: {label}, Predicted: {predicted.item()}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "XlSE7kFCmMig",
        "outputId": "b874ffbf-407c-44ba-d752-0768dcdfe1fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EX40kdaVnnU"
      },
      "source": [
        "### Average Pooling Test Accuracy < Max Pooling Test Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzVO-G0yVnnU"
      },
      "source": [
        "### Model C:\n",
        "- 2 Convolutional Layers\n",
        "    - **Valid Padding** (smaller output size)\n",
        "- 2 **Max Pooling** Layers\n",
        "- 1 Fully Connected Layer\n",
        "<img src=\"./images/cnn10-5.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "<img src=\"./images/cnn10-6n.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- Step 3: Create Model Class\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBLgc6hCVnnU",
        "outputId": "02ca0b7c-948d-4ad7-a118-6e0e7c804855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 24, 24]             416\n",
            "              ReLU-2           [-1, 16, 24, 24]               0\n",
            "         MaxPool2d-3           [-1, 16, 12, 12]               0\n",
            "            Conv2d-4             [-1, 32, 8, 8]          12,832\n",
            "              ReLU-5             [-1, 32, 8, 8]               0\n",
            "         MaxPool2d-6             [-1, 32, 4, 4]               0\n",
            "            Linear-7                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 18,378\n",
            "Trainable params: 18,378\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.19\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 0.27\n",
            "----------------------------------------------------------------\n",
            "Iteration: 500. Loss: 0.3374074697494507. Accuracy: 88.56999969482422\n",
            "Iteration: 1000. Loss: 0.2915293872356415. Accuracy: 92.58000183105469\n",
            "Iteration: 1500. Loss: 0.24209442734718323. Accuracy: 94.37999725341797\n",
            "Iteration: 2000. Loss: 0.16651950776576996. Accuracy: 95.37999725341797\n",
            "Iteration: 2500. Loss: 0.22416360676288605. Accuracy: 95.95999908447266\n",
            "Iteration: 3000. Loss: 0.13524512946605682. Accuracy: 96.5\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Max pool 1\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Max pool 2\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        self.fc1 = nn.Linear(32 * 4 * 4, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution 1\n",
        "        out = self.cnn1(x)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Max pool 1\n",
        "        out = self.maxpool1(out)\n",
        "\n",
        "        # Convolution 2\n",
        "        out = self.cnn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Max pool 2\n",
        "        out = self.maxpool2(out)\n",
        "\n",
        "        # Resize\n",
        "        # Original size: (100, 32, 7, 7)\n",
        "        # out.size(0): 100\n",
        "        # New out size: (100, 32*7*7)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        out = self.fc1(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "\n",
        "from torchsummary import summary\n",
        "model = CNNModel()\n",
        "\n",
        "#Shows what the model looks like\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images as Variable\n",
        "        images = images.requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images to a Torch Variable\n",
        "                images = images.requires_grad_()\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pick a random index from the test dataset\n",
        "rand_index = random.randint(0, len(test_dataset) - 1)\n",
        "image, label = test_dataset[rand_index]\n",
        "\n",
        "# Prepare image for the model (add batch dimension)\n",
        "input_image = image.unsqueeze(0)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Show the image and prediction\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"True Label: {label}, Predicted: {predicted.item()}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "_Mh2GN9emKhH",
        "outputId": "8bd4a2b2-1084-4690-95ab-a079b2364de8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3SqekHSVnnU"
      },
      "source": [
        "### Summary of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsHdB98yVnnU"
      },
      "source": [
        "\n",
        "\n",
        "Model A | Model B | Model C\n",
        "------------|--------- |------------------\n",
        "Max Pooling      | Average Pooling       |Average Pooling  \n",
        "Same Padding | Same Padding | Valid Padding\n",
        "97.04% | 93.59% | 96.5%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUnwRv4vVnnU"
      },
      "source": [
        "| All Models |\n",
        "|------|\n",
        "| INPUT $\\rightarrow$ CONV $\\rightarrow$ POOL $\\rightarrow$ CONV $\\rightarrow$ POOL $\\rightarrow$ FC |\n",
        "| Convolution Kernel Size = 5 x 5 |\n",
        "| Convolution Kernel Stride = 1 |\n",
        "| Pooling Kernel Size = 2 x 2 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRiv2fXMVnnU"
      },
      "source": [
        "\n",
        "### Deep Learning\n",
        "- 3 ways to expand a convolutional neural network\n",
        "    - More convolutional layers\n",
        "    - Less aggressive downsampling\n",
        "        - Smaller kernel size for pooling (gradually downsampling)\n",
        "    - More fully connected layers\n",
        "- Cons\n",
        "    - Need a larger dataset\n",
        "        - Curse of dimensionality\n",
        "    - Does not necessarily mean higher accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxyqRIlEVnnV"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tJdpKVFVnnd"
      },
      "source": [
        "- Transition from **Feedforward Neural Network**\n",
        "    - Addition of **Convolutional** & **Pooling** Layers before Linear Layers\n",
        "- One **Convolutional** Layer Basics\n",
        "- One **Pooling** Layer Basics\n",
        "    - Max pooling\n",
        "    - Average pooling\n",
        "- **Padding **\n",
        "- **Output Dimension** Calculations and Examples\n",
        "    -  $$ O = \\frac {W - K + 2P}{S} + 1$$\n",
        "- Convolutional Neural Networks\n",
        "    - **Model A**: 2 Conv + 2 Max pool + 1 FC\n",
        "        - Same Padding\n",
        "    - **Model B**: 2 Conv + 2 Average pool + 1 FC\n",
        "        - Same Padding\n",
        "    - **Model C**: 2 Conv + 2 Max pool + 1 FC\n",
        "        - Valid Padding\n",
        "\n",
        "- Ways to Expand Model’s **Capacity**\n",
        "    - More convolutions\n",
        "    - Gradual pooling\n",
        "    - More fully connected layers\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "pytorch_latest",
      "language": "python",
      "name": "pytorch_latest"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
