{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smojumder018/SUPREME/blob/main/2.2%20FFNN_MNIST_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc_eGzBSIQXv"
      },
      "source": [
        "\n",
        "\n",
        "# Feedforward Neural Network with PyTorch\n",
        "## About Feedforward Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XjNvVF5IQXx"
      },
      "source": [
        "\n",
        "       \n",
        "##1. Introduction\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=142_j-YDgvnjrwOb7UGSuM6Hsx7u_iJTI)\n",
        "\n",
        "### Non-linear activation function\n",
        "\n",
        "- Function: takes a number & perform mathematical operation\n",
        "- Common Types of Non-linearity\n",
        "    - ReLUs (Rectified Linear Units)      \n",
        "    - Sigmoid     \n",
        "    - Tanh\n",
        "\n",
        "#### Sigmoid (Logistic)\n",
        "- $\\sigma(x) = \\frac{1}{1 + e^{-x}}$\n",
        "- Input number $\\rightarrow$ [0, 1]\n",
        "    - Large negative number $\\rightarrow$ 0\n",
        "    - Large positive number $\\rightarrow$ 1\n",
        "- Cons:\n",
        "    1. Activation saturates at 0 or 1 with **gradients $\\approx$ 0**\n",
        "        - No signal to update weights $\\rightarrow$ **cannot learn**\n",
        "        - Solution: Have to carefully initialize weights to prevent this\n",
        "    2. Outputs not centered around 0\n",
        "        - If output always positive $\\rightarrow$ gradients always positive or negative $\\rightarrow$ **bad for gradient updates**\n",
        "\n",
        "#### Tanh\n",
        "- $\\tanh(x) = 2 \\sigma(2x) -1$\n",
        "    - A scaled sigmoid function\n",
        "- Input number $\\rightarrow$ [-1, 1]\n",
        "- Cons:\n",
        "    1. Activation saturates at 0 or 1 with **gradients $\\approx$ 0**\n",
        "        - No signal to update weights $\\rightarrow$ **cannot learn**\n",
        "        - **Solution**: Have to carefully initialize weights to prevent this\n",
        "\n",
        "\n",
        "#### ReLUs\n",
        "- $f(x) = \\max(0, x)$\n",
        "- Pros:\n",
        "    1. Accelerates convergence $\\rightarrow$ **train faster**\n",
        "    2. **Less computationally expensive operation** compared to Sigmoid/Tanh exponentials\n",
        "- Cons:\n",
        "    1. Many ReLU units \"die\" $\\rightarrow$ **gradients = 0** forever\n",
        "        - **Solution**: careful learning rate choice\n",
        "      \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. MNIST Dataset\n",
        "![](https://drive.google.com/uc?export=view&id=1Esgjfx-jfstlL0h1dlfBvcjGVGSFzMrw)\n",
        "\n",
        "The MNIST dataset is a benchmark dataset used for training and testing image processing systems, especially in the field of machine learning and deep learning. It is particularly popular for testing classification algorithms. It is a collection of images of hand written numbers.\n",
        "\n",
        "**Datasets:**\n",
        "\n",
        "Set| Number of Images\n",
        "---|---\n",
        "Training|60,000\n",
        "Testing|10,000\n",
        "\n",
        "**Image Properties:**\n",
        "\n",
        "*Image Size: 28 x 28 pixels\n",
        "\n",
        "*Pixel Values: 0 (black) to 255 (white); typically normalized to [0, 1] for model input\n",
        "\n",
        "*Color Format: Grayscale (1 channel)\n"
      ],
      "metadata": {
        "id": "_dOZ-rXivS3r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuGoBizUIQXy"
      },
      "source": [
        "## 3. Building a Feedforward Neural Network with PyTorch\n",
        "\n",
        "### Model A: 1 Hidden Layer Feedforward Neural Network (Sigmoid Activation)\n",
        "\n",
        "\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- Step 3: Create Model Class\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzr0qN7AIQXy"
      },
      "source": [
        "### Step 1: Loading MNIST Train Dataset\n",
        "**Images from 1 to 9**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  What is PyTorch?\n",
        "\n",
        "**PyTorch** is an open-source deep learning library developed by Facebook.\n",
        "\n",
        "\n",
        "\n",
        "###  Key Features:\n",
        "\n",
        "- **Easy to use**: Pythonic and intuitive\n",
        "- **Dynamic computation graph**: Builds the graph on the fly (great for debugging)\n",
        "- **GPU support**: Use CUDA for fast training\n",
        "- **Strong community**: Well-documented and widely used in research\n",
        "\n",
        "\n",
        "\n",
        "###  Core Components:\n",
        "\n",
        "- `Tensor`: Like NumPy arrays, but with GPU support\n",
        "- `autograd`: Automatically calculates gradients\n",
        "- `nn.Module`: For building neural networks\n",
        "- `optimizer`: Updates weights (e.g., SGD, Adam)\n",
        "- `loss function`: Measures how wrong the model is (e.g., CrossEntropy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RJ1gbaUOLCUl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUzXyJjSIQXy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAiuWftjIQXz"
      },
      "outputs": [],
      "source": [
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- root is the path where the train/test data is stored,\n",
        "\n",
        "- train specifies training or test dataset,\n",
        "\n",
        "- download=True downloads the data from the internet if it’s not available at root.\n",
        "\n",
        "- transform and target_transform specify the feature and label transformations"
      ],
      "metadata": {
        "id": "RMTIwiasAjMR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr851gobIQXz"
      },
      "source": [
        "### Step 2: Make Dataset Iterable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "- **Epoch** = 1 full pass through the entire training dataset\n",
        "- **Iteration** = 1 update of the model (i.e., one batch passed through the network)\n",
        "\n",
        "#Example\n",
        "\n",
        "\n",
        "- **Dataset size**: 60,000  \n",
        "- **Batch size**: 100  \n",
        "- **Epochs**: 5  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- **Iterations per epoch** = 60,000 / 100 = **600**\n",
        "- **Total iterations** = 600 × 5 = **3,000**\n",
        "\n"
      ],
      "metadata": {
        "id": "4sMiozlDMuo6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCLjdViBIQX0"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = 5\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tETLumT4IQX0"
      },
      "source": [
        "### Step 3: Create Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvkDHsQuIQX0"
      },
      "outputs": [],
      "source": [
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # Non-linearity\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        # Linear function (readout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function  # LINEAR\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity  # NON-LINEAR\n",
        "        out = self.sigmoid(out)\n",
        "        # Linear function (readout)  # LINEAR\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeiTuFxjIQX0"
      },
      "source": [
        "### Step 4: Instantiate Model Class\n",
        "- **Input** dimension: **784**\n",
        "    - Size of image\n",
        "    - 28 x 28 = 784\n",
        "- **Output** dimension: **10**\n",
        "    - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
        "- **Hidden** dimension: **100**\n",
        "    - Can be any number\n",
        "    - Similar term\n",
        "        - Number of neurons\n",
        "        - Number of non-linear activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgsnDobjIQX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde94199-0d8f-450a-a16b-94ab24549cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "           Sigmoid-2                  [-1, 100]               0\n",
            "            Linear-3                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "#Shows what the model looks like\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter number refers to the number of trainable weights and biases in each layer of the NN\n"
      ],
      "metadata": {
        "id": "9vxYJE219euq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw1YQ49lIQX1"
      },
      "source": [
        "### Step 5: Instantiate Loss Class\n",
        "- Feedforward Neural Network: **Cross Entropy Loss**\n",
        "    - _Logistic Regression_: **Cross Entropy Loss**\n",
        "    - _Linear Regression_: **MSE**\n",
        "   \n",
        "\n",
        "| Feature           | Cross-Entropy Loss         | Mean Squared Error (MSE) |\n",
        "|-------------------|----------------------------|---------------------------|\n",
        "| Use Case          | Classification             | Regression                |\n",
        "| Output Type       | Probabilities (e.g. softmax) | Continuous values         |\n",
        "| Target Format     | One-hot encoded             | Numerical values          |\n",
        "| Penalizes Errors  | Strongly (esp. wrong confident guesses) | Mildly          |\n",
        "| Training Behavior | Faster, more stable         | Slower for classification |\n",
        "\n",
        "\n",
        "- **Use Cross-Entropy** for **classification** (e.g. MNIST).\n",
        "- **Use MSE** for **regression** (e.g. predicting temperatures).\n",
        "\n",
        "> Cross-Entropy is better at teaching the model to output the correct **class probabilities**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z--jcCLsIQX1"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXuNSoj6IQX1"
      },
      "source": [
        "### Step 6: Instantiate Optimizer Class\n",
        "\n",
        "\n",
        "- The goal of training is to **minimize the loss** (i.e., improve model performance).\n",
        "- The gradient $\\nabla_\\theta$ tells us the **direction of steepest increase** in loss.\n",
        "- To reduce the loss, we move in the **opposite direction** of the gradient.\n",
        "\n",
        "\n",
        "\n",
        "### Simplified Update Rule:\n",
        "\n",
        "$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta$\n",
        "\n",
        "Where:\n",
        "- $\\theta$ = model parameters  \n",
        "- $\\eta$ = learning rate (step size)  \n",
        "- $\\nabla_\\theta$ = gradient of the loss w.r.t. $\\theta$\n",
        "\n",
        "\n",
        "### Even Simpler:\n",
        "\n",
        "```python\n",
        "parameters = parameters - learning_rate * parameters_gradients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqGcC6HVIQX1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvyXZ--KIQX1"
      },
      "source": [
        "### Step 7: Train Model\n",
        "- Process\n",
        "    1. Convert inputs to tensors with gradient accumulation capabilities\n",
        "    2. Clear gradient buffers\n",
        "    3. Get output given inputs\n",
        "    4. Get loss\n",
        "    5. Get gradients w.r.t. parameters\n",
        "    6. Update parameters using gradients\n",
        "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "    7. REPEAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-KqT06WIQX1",
        "outputId": "1f88471e-3c86-4d61-cf02-09324266abae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 0.6986587047576904. Accuracy: 86.12000274658203\n",
            "Iteration: 1000. Loss: 0.6583812236785889. Accuracy: 89.22000122070312\n",
            "Iteration: 1500. Loss: 0.45578262209892273. Accuracy: 90.44000244140625\n",
            "Iteration: 2000. Loss: 0.3819163143634796. Accuracy: 91.16999816894531\n",
            "Iteration: 2500. Loss: 0.29614630341529846. Accuracy: 91.68000030517578\n",
            "Iteration: 3000. Loss: 0.26872825622558594. Accuracy: 92.05000305175781\n"
          ]
        }
      ],
      "source": [
        "iter = 0\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images with gradient accumulation capabilities\n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images with gradient accumulation capabilities\n",
        "                images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of the models predictions"
      ],
      "metadata": {
        "id": "D1QF0T2VJOtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Pick a random index from the test dataset\n",
        "rand_index = random.randint(0, len(test_dataset) - 1)\n",
        "image, label = test_dataset[rand_index]\n",
        "\n",
        "# Prepare image for model input\n",
        "input_image = image.view(-1, 28*28)\n",
        "\n",
        "# Get model prediction\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Display the image and prediction\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted.item()}, Actual: {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "po1xhm7aJNtp",
        "outputId": "9d5f59b4-d838-47a1-e2dd-7d272ce04527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O2RfVoOIQX1"
      },
      "source": [
        "### Model B: 1 Hidden Layer Feedforward Neural Network (Tanh Activation)\n",
        "<img src=\"./images/nn1.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- **Step 3: Create Model Class**\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28daFbRuIQX2",
        "outputId": "4a814df9-e140-4ff7-e050-448f7156e657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "              Tanh-2                  [-1, 100]               0\n",
            "            Linear-3                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n",
            "Iteration: 500. Loss: 0.5058755278587341. Accuracy: 91.0999984741211\n",
            "Iteration: 1000. Loss: 0.2824786901473999. Accuracy: 92.5999984741211\n",
            "Iteration: 1500. Loss: 0.28009945154190063. Accuracy: 93.5199966430664\n",
            "Iteration: 2000. Loss: 0.14435920119285583. Accuracy: 94.0\n",
            "Iteration: 2500. Loss: 0.19282729923725128. Accuracy: 94.77999877929688\n",
            "Iteration: 3000. Loss: 0.18061700463294983. Accuracy: 95.25\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # Non-linearity\n",
        "        self.tanh = nn.Tanh()\n",
        "        # Linear function (readout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity\n",
        "        out = self.tanh(out)\n",
        "        # Linear function (readout)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "from torchsummary import summary\n",
        "#Shows what the model looks like\n",
        "summary(model, input_size=(784,))\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images with gradient accumulation capabilities\n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images with gradient accumulation capabilities\n",
        "                images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Pick a random index from the test dataset\n",
        "rand_index = random.randint(0, len(test_dataset) - 1)\n",
        "image, label = test_dataset[rand_index]\n",
        "\n",
        "# Prepare image for model input\n",
        "input_image = image.view(-1, 28*28)\n",
        "\n",
        "# Get model prediction\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Display the image and prediction\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted.item()}, Actual: {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cMQh6RX60A-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCJSJBDeIQX2"
      },
      "source": [
        "### Model C: 1 Hidden Layer Feedforward Neural Network (ReLU Activation)\n",
        "<img src=\"./images/nn1.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- **Step 3: Create Model Class**\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDKdVmayIQX2",
        "outputId": "36b955ef-5692-438b-8b9b-870e9ebac858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "              ReLU-2                  [-1, 100]               0\n",
            "            Linear-3                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n",
            "Iteration: 500. Loss: 0.37251144647598267. Accuracy: 91.63999938964844\n",
            "Iteration: 1000. Loss: 0.2487357258796692. Accuracy: 93.16999816894531\n",
            "Iteration: 1500. Loss: 0.2486622929573059. Accuracy: 94.08999633789062\n",
            "Iteration: 2000. Loss: 0.12761478126049042. Accuracy: 94.80000305175781\n",
            "Iteration: 2500. Loss: 0.21595342457294464. Accuracy: 95.18000030517578\n",
            "Iteration: 3000. Loss: 0.20631448924541473. Accuracy: 95.75\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # Non-linearity\n",
        "        self.relu = nn.ReLU()\n",
        "        # Linear function (readout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity\n",
        "        out = self.relu(out)\n",
        "        # Linear function (readout)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "from torchsummary import summary\n",
        "#Shows what the model looks like\n",
        "summary(model, input_size=(784,))\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images with gradient accumulation capabilities\n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images with gradient accumulation capabilities\n",
        "                images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Pick a random index from the test dataset\n",
        "rand_index = random.randint(0, len(test_dataset) - 1)\n",
        "image, label = test_dataset[rand_index]\n",
        "\n",
        "# Prepare image for model input\n",
        "input_image = image.view(-1, 28*28)\n",
        "\n",
        "# Get model prediction\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Display the image and prediction\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted.item()}, Actual: {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Iz-dsaH0DE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J7eKyQqIQX2"
      },
      "source": [
        "### Model D: 2 Hidden Layer Feedforward Neural Network (ReLU Activation)\n",
        "\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- **Step 3: Create Model Class**\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaI-3FnsIQX2",
        "outputId": "bb9097a2-8b0a-4092-e8b0-84bc6abecfec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "              ReLU-2                  [-1, 100]               0\n",
            "            Linear-3                  [-1, 100]          10,100\n",
            "              ReLU-4                  [-1, 100]               0\n",
            "            Linear-5                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 89,610\n",
            "Trainable params: 89,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.34\n",
            "Estimated Total Size (MB): 0.35\n",
            "----------------------------------------------------------------\n",
            "Iteration: 500. Loss: 0.36210355162620544. Accuracy: 91.48999786376953\n",
            "Iteration: 1000. Loss: 0.1846974939107895. Accuracy: 93.70999908447266\n",
            "Iteration: 1500. Loss: 0.16324417293071747. Accuracy: 94.5999984741211\n",
            "Iteration: 2000. Loss: 0.16899342834949493. Accuracy: 95.47000122070312\n",
            "Iteration: 2500. Loss: 0.05157177895307541. Accuracy: 96.1500015258789\n",
            "Iteration: 3000. Loss: 0.042060140520334244. Accuracy: 96.4800033569336\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function 1: 784 --> 100\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # Non-linearity 1\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Linear function 2: 100 --> 100\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        # Non-linearity 2\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Linear function 3 (readout): 100 --> 10\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function 1\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity 1\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Linear function 2\n",
        "        out = self.fc2(out)\n",
        "        # Non-linearity 2\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Linear function 3 (readout)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "from torchsummary import summary\n",
        "#Shows what the model looks like\n",
        "summary(model, input_size=(784,))\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images with gradient accumulation capabilities\n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "        labels = labels\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images with gradient accumulation capabilities\n",
        "                images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Pick a random index from the test dataset\n",
        "rand_index = random.randint(0, len(test_dataset) - 1)\n",
        "image, label = test_dataset[rand_index]\n",
        "\n",
        "# Prepare image for model input\n",
        "input_image = image.view(-1, 28*28)\n",
        "\n",
        "# Get model prediction\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Display the image and prediction\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted.item()}, Actual: {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tSIjPdUK0EfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oViRs-yCIQX3"
      },
      "source": [
        "### Model E: 3 Hidden Layer Feedforward Neural Network (ReLU Activation)\n",
        "<img src=\"./images/nn3.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- **Step 3: Create Model Class**\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goPcNY4ZIQX3",
        "outputId": "5980aa99-27c2-4c9b-eb42-70be3b4fbc5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "              ReLU-2                  [-1, 100]               0\n",
            "            Linear-3                  [-1, 100]          10,100\n",
            "              ReLU-4                  [-1, 100]               0\n",
            "            Linear-5                  [-1, 100]          10,100\n",
            "              ReLU-6                  [-1, 100]               0\n",
            "            Linear-7                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 99,710\n",
            "Trainable params: 99,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.38\n",
            "Estimated Total Size (MB): 0.39\n",
            "----------------------------------------------------------------\n",
            "Iteration: 500. Loss: 0.46316471695899963. Accuracy: 87.73999786376953\n",
            "Iteration: 1000. Loss: 0.22544799745082855. Accuracy: 94.05999755859375\n",
            "Iteration: 1500. Loss: 0.2285025268793106. Accuracy: 95.04000091552734\n",
            "Iteration: 2000. Loss: 0.21926330029964447. Accuracy: 95.5999984741211\n",
            "Iteration: 2500. Loss: 0.08138717710971832. Accuracy: 96.68000030517578\n",
            "Iteration: 3000. Loss: 0.1369541734457016. Accuracy: 96.73999786376953\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function 1: 784 --> 100\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # Non-linearity 1\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Linear function 2: 100 --> 100\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        # Non-linearity 2\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Linear function 3: 100 --> 100\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        # Non-linearity 3\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        # Linear function 4 (readout): 100 --> 10\n",
        "        self.fc4 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function 1\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity 1\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Linear function 2\n",
        "        out = self.fc2(out)\n",
        "        # Non-linearity 2\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Linear function 2\n",
        "        out = self.fc3(out)\n",
        "        # Non-linearity 2\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        # Linear function 4 (readout)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "from torchsummary import summary\n",
        "#Shows what the model looks like\n",
        "summary(model, input_size=(784,))\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images with gradient accumulation capabilities\n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images with gradient accumulation capabilities\n",
        "                images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Pick a random index from the test dataset\n",
        "rand_index = random.randint(0, len(test_dataset) - 1)\n",
        "image, label = test_dataset[rand_index]\n",
        "\n",
        "# Prepare image for model input\n",
        "input_image = image.view(-1, 28*28)\n",
        "\n",
        "# Get model prediction\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Display the image and prediction\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted.item()}, Actual: {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "tUDa3aGc0Foj",
        "outputId": "7d314ca6-1952-4a7d-f8ae-b1421a1a32f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu0PfFcrIQX3"
      },
      "source": [
        "### Deep Learning\n",
        "- 2 ways to expand a neural network\n",
        "    - More non-linear activation units (neurons)\n",
        "    - More hidden layers\n",
        "- Cons\n",
        "    - Need a larger dataset\n",
        "\n",
        "    - Does not necessarily mean higher accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8xjzNmmIQYA"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UULiiwvIQYA"
      },
      "source": [
        "\n",
        "- **Types** of Activation functions\n",
        "    - Sigmoid\n",
        "    - Tanh\n",
        "    - ReLU\n",
        "- Feedforward Neural Network **Models**\n",
        "    - Model A: 1 hidden layer (**sigmoid** activation)\n",
        "    - Model B: 1 hidden layer (**tanh** activation)\n",
        "    - Model C: 1 hidden layer (**ReLU** activation)\n",
        "    - Model D: **2 hidden** layers (ReLU activation)\n",
        "    - Model E: **3 hidden** layers (ReLU activation)\n",
        "\n",
        "- Ways to Expand Model’s **Capacity**\n",
        "    - More non-linear activation units (**neurons**)\n",
        "    - More hidden **layers**\n",
        "- **Cons** of Expanding Capacity\n",
        "    - Need more **data**\n",
        "    - Does not necessarily mean higher **accuracy**\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "pytorch_latest",
      "language": "python",
      "name": "pytorch_latest"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}